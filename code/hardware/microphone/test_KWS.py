import tensorflow as tf
import numpy as np
import wave
import pathlib
import time

# --- é…ç½®åŒºåŸŸ ---
MODEL_PATH = '/home/linaro/smart_cane_project/hardware/microphone/tensorflow/model2/saved'
TEST_WAV_FILE = '/home/linaro/smart_cane_project/hardware/microphone/yes.wav' # ä½¿ç”¨ä½ ç¡®è®¤å¯ç”¨çš„æ–‡ä»¶

# --- ä¸»é€»è¾‘ ---

def load_model(model_path):
    """åŠ è½½ TensorFlow SavedModelã€‚"""
    print(f"ðŸš€ [1/4] æ­£åœ¨ä»Ž '{model_path}' åŠ è½½æ¨¡åž‹...")
    if not pathlib.Path(model_path).exists():
        print(f"âŒ é”™è¯¯ï¼šæ¨¡åž‹è·¯å¾„ä¸å­˜åœ¨ï¼")
        return None
    try:
        start_time = time.time()
        loaded_model = tf.saved_model.load(model_path)
        end_time = time.time()
        print(f"âœ… æ¨¡åž‹åŠ è½½æˆåŠŸï¼è€—æ—¶: {end_time - start_time:.2f} ç§’ã€‚")
        return loaded_model
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡åž‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

def load_wav_to_bytes(wav_path):
    """ä»ŽWAVæ–‡ä»¶åŠ è½½åŽŸå§‹éŸ³é¢‘æ•°æ®åˆ°å†…å­˜å­—èŠ‚ä¸²ã€‚"""
    print(f"ðŸŽ§ [2/4] æ­£åœ¨ä»Ž '{wav_path}' åŠ è½½éŸ³é¢‘æ•°æ®åˆ°å†…å­˜...")
    wav_path_obj = pathlib.Path(wav_path)
    if not wav_path_obj.exists():
        print(f"âŒ é”™è¯¯ï¼šæµ‹è¯•WAVæ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return None, None
    try:
        with wave.open(str(wav_path_obj), 'rb') as wf:
            frames = wf.readframes(wf.getnframes())
            params = wf.getparams()
            print(f"âœ… éŸ³é¢‘åŠ è½½æˆåŠŸã€‚æ ¼å¼: {params.nchannels}å£°é“, {params.framerate}Hz, {params.sampwidth*8}-bit")
            if params.nchannels != 1 or params.framerate != 16000:
                print("âš ï¸ è­¦å‘Šï¼šéŸ³é¢‘æ–‡ä»¶ä¸æ˜¯16kHzå•å£°é“ï¼Œé¢„æµ‹ç»“æžœå¯èƒ½ä¸å‡†ç¡®ï¼")
            return frames, params
    except Exception as e:
        print(f"âŒ è¯»å–WAVæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None, None

def predict_from_memory(model, audio_bytes):
    """ã€æ ¸å¿ƒæµ‹è¯•å‡½æ•°ã€‘ç›´æŽ¥ä»Žå†…å­˜ä¸­çš„éŸ³é¢‘å­—èŠ‚è¿›è¡Œé¢„æµ‹ã€‚"""
    print("ðŸ§  [3/4] æ­£åœ¨å†…å­˜ä¸­å‡†å¤‡æ•°æ®å¹¶æ‰§è¡Œé¢„æµ‹...")
    label_names = ['backward', 'down', 'follow', 'forward', 'go', 'left', 'no', 'noise', 'off', 'on', 'right', 'stop', 'up', 'yes']

    if not audio_bytes or not model:
        print("âŒ æ— æ³•é¢„æµ‹ï¼šæ¨¡åž‹æˆ–éŸ³é¢‘æ•°æ®ä¸ºç©ºã€‚")
        return

    try:
        audio_np = np.frombuffer(audio_bytes, dtype=np.int16)
        audio_float = audio_np.astype(np.float32) / 32768.0

        target_len = 16000
        if len(audio_float) > target_len:
            audio_float = audio_float[:target_len]
        elif len(audio_float) < target_len:
            audio_float = np.pad(audio_float, (0, target_len - len(audio_float)), 'constant')
        
        audio_tensor = tf.constant(audio_float, dtype=tf.float32)

        # --- æ ¸å¿ƒä¿®å¤ï¼šå¢žåŠ ä¸€ä¸ªâ€œæ‰¹æ¬¡â€ç»´åº¦ (batch dimension) ---
        # å°† (16000,) å˜ä¸º (1, 16000)
        audio_tensor = tf.expand_dims(audio_tensor, 0) 
        # ----------------------------------------------------

        print("    [Info] æ•°æ®å·²è½¬æ¢ä¸ºTensorã€‚Shape:", audio_tensor.shape)
        print("    [Info] æ­£åœ¨è°ƒç”¨æ¨¡åž‹è¿›è¡ŒæŽ¨ç†...")
        predictions = model(audio_tensor)
        print("    [Info] æ¨¡åž‹æŽ¨ç†å®Œæˆã€‚")

        predicted_logits = predictions['predictions']
        probabilities = tf.nn.softmax(predicted_logits).numpy().flatten()
        predicted_class_id = np.argmax(probabilities)
        predicted_word = label_names[predicted_class_id]
        confidence = probabilities[predicted_class_id]

        print("\n" + "="*40)
        print(f"ðŸŽ¯ [4/4] é¢„æµ‹ç»“æžœ")
        print(f"    - è¯†åˆ«å‡ºçš„è¯: '{predicted_word}'")
        print(f"    - ç½®ä¿¡åº¦: {confidence:.2%}")
        print("="*40 + "\n")
        print("âœ… æµ‹è¯•æˆåŠŸï¼šæ¨¡åž‹å¯ä»¥æŽ¥å—å†…å­˜ä¸­çš„éŸ³é¢‘æ•°æ®ï¼")

    except Exception as e:
        print("\n" + "!"*40)
        print(f"âŒ åœ¨å†…å­˜é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        print("!"*40 + "\n")
        print("ðŸ›‘ æµ‹è¯•å¤±è´¥ã€‚")

if __name__ == "__main__":
    print("--- KWSå†…å­˜ç›´ä¼ é¢„æµ‹æµ‹è¯• ---")
    
    kws_model = load_model(MODEL_PATH)
    if not kws_model:
        exit()

    wav_bytes, wav_params = load_wav_to_bytes(TEST_WAV_FILE)
    if not wav_bytes:
        exit()

    predict_from_memory(kws_model, wav_bytes)